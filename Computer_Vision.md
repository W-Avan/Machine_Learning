+ #### 数据驱动方法  
> + 图像处理任务：计算机视觉的核心任务  
> 当你做图像分类时，分类系统接受一些输入图像，并且系统清楚了一些已经确定的分类或者标签的集合，计算机的工作就是看图片，并且给它分配其中一些固定的分类标签  
> + The Problem: Semantic Gap(语义鸿沟)  
> 对于猫咪的概念或者它的标签，是我们赋给图像的一个语义标签，一只猫咪的语义概念和这些计算机实际看到的像素之间有着巨大的差距  
> + Challenges:   
>> + Viewpoint variation(视角):由于微小的方式改变图片，将导致像素网格整个发生变化，我们的算法需要对这些变化鲁棒  
>> + illumination(照明问题):  在场景中会有不同的照明条件，但在不同的光照下仍要识别出是同一只猫， 算法需要对这些变化鲁棒  
>> + Deformation(变形): 一只猫可能有千奇百怪的姿势和位置，对于不同的形变情形，我们的算法也应该是鲁棒的  
>> + Occlusion(遮挡)：  
>> + Background clutter(背景混乱):  
>> + Intraclass variation(类内差异): 一些猫因为颜色形态大小等，引起的视觉差异  
> **Data-Driven Approach(数据驱动方法):**
>> 1.利用搜索引擎抓取大量的相关图片数据集  
>> 2.训练机器来分类这些图片  ,总结生成一个模型，总结识别出这些不同类的对象的核心知识要素  
>> 3.利用这些模型识别新的图片  
>> 两个函数，一个是训练函数(接受图片和标签)，然后输入模型； 另一种是预测函数，接受模型，对图片种类进行预测  
> First classifier(分类器):**Nearest Neighbor(最近邻)**
> **L1距离(曼哈顿距离)：** 对图像的单个像素进行比较，用测试的图像减去训练图像的像素差的绝对值，所有差值相加求和(如果转动坐标轴，会改变点之间的L1距离)  
+ #### K-Nearest Neignbors(K-邻近算法)：  
>&emsp; 它不只找最最近的点，我们会做一些特殊操作，根据距离量度，找到最近的 K 个点，然后在这些相邻点中进行投票，预测出结果。(通常给K赋较大的值，这样会使决策边界更加平滑)  
> &emsp; **L2距离(欧氏距离)：** 取平方和的平方根，并且把这个作为距离(改变坐标轴对L2距离毫无影响)  
> &emsp; K 和距离度量的选择，称之为**超参数(hyperparameters)** , 无法从书籍中学习到，需要提前为算法做出选择  
+ ## 线性分类(Linear Classification)  
> **f(x, W) = Wx + b**  
>  &emsp;线性分类输入参数分类的一种，所有的训练数据中的经验知识都体现在参数矩阵 W 中，而 W 通过训练过程得到，我们拿到一张图，拉伸成一个长的向量，这里的图片假设叫做 x ，(例：拉伸成一个三维长向量(32, 32, 3) 其中高度和宽度是32像素，3则代表颜色通道 红、绿、 蓝)，还存在一个参数矩阵 W ，把这个代表图片像素的列向量当作输入，然后转化成10个数字评分  
> 线性分类可以解释为每个种类的学习模板  
+ ## 损失函数  
> 可以用一个函数把 W 当做输入，然后看一下得分，定量的估计 W 的好坏 这个函数被称为**损失函数**, 记作 L_i  
> + SVM loss:  
>>&emsp;对一个训练样例，若真实种类大于某一种类分数超过一个安全值，则这两种类的损失(loss)为 0 ；若不大于安全值，则求出差值并加上安全值，则为该两种类的损失值，将该样例与训练种类的损失值相加, 最终对于整个训练数据集的损失函数，是这些不同的样例损失函数的平均值    
>> + 标准损失函数拥有两个项，数据丢失项 和 正则项，这里有一些超参数 λ 用来平衡这两个项  
>> + 正则项是关于 W 的函数，为约束得到模型的唯一解，同时防止模型过拟合  
>> + L1度量复杂度的方式，有可能是非零元素的个数； 而L2更多的烤炉的是 W 整体布局，防止过拟合
> + doftmax loss(多项逻辑斯蒂回归)  
>> 用同 SVM 损失函数中算出的分数， 首先**指数化处理**(都变成正数),然后进行**归一化**(以保证他们的和为1)， L_i = -log(0.13) (0.13为真实情况对应的值)  
+ ## Optimization(优化)  
> + Strategy #1:随机采样，让后将他们输入损失函数
> + Strategy #2:Follow the slope  
> **梯度**  
> 找到 L 在 W 方向上的梯度  
> 沿着最陡的下降方向，即梯度的负方向，来一步步迭代，这样就能沿着损失函数从上往下走到最低点，走到了损失函数的等高轮廓的最低点  
> + 使用有限差分估计来计算数值梯度  
> + 使用解析梯度计数  
> + #### Mini-batch SGD(最小批量随机梯度下降)
>> &emsp;它的步骤是对数据进行连续的批量抽样，我们通过使用计算图或神经网络将数据进行正向传播，最终我们得到损失值，通过整个网络的反向传播来计算梯度，然后使用这个梯度来更新，网络中的参数或者权重。

+ ## 介绍神经网络-反向传播  
> + 计算图(框架): 我们用这类图来表示任意函数，其中图的节点，表示我们要执行的每一步计算
> + 反向传播是链式法则的递归调用，我们从计算图的最后面开始，从后往前，计算所有的梯度  
> + add gate: 加法节点连接了两个分支，获取上游梯度，并且知识分发和传递完全相同的梯度给相连的两个分支  
> + max gate: max 门将获取梯度，并且将其路由到它其中一个分支，另一分支梯度为 0  
> + mul gate: 获取上游梯度，然后根据另一个分支的值对其缩放  
> + 当有一个节点连接到多个节点时，梯度会在这个节点累加，得到其总上游梯度值    
+ ## 介绍神经网络-神经网络  
> + 神经网络就是：  
 &emsp;由简单函数构成的一组函数，在顶层堆叠在一起，我们用一种层次化的方式将它们堆叠起来，为了形成一个更复杂的非线性函数,多阶段分层计算   
 > + 激活函数，为了增加神经网络模型的非线性
+ ## 卷积神经网络  
> &emsp;**这是一种特殊的网络，它使用卷积层在贯穿整个网络的层次结构中，保持(输入)的空间结构，卷积层输出的每个激活图，是通过使用一个权重卷积核，在输入
(矩阵)的空间位置上滑动而生成的**
> + #### 卷积和池化  
>> 卷积层，它和全连接层(把32\*32\*3的 图，所有像素展开，得到一个3072维的向量)的主要差别，可以保全空间结构 ， 这里的权重时一些小的卷积核。  
>> + 我们的 ConvNet 基本上是由多个卷积层组成的一个序列，它们依次堆叠，就像我们之前在神经网络中，那样堆叠简单的线性层一样,之后我们将用激活函数对其进行逐一处理  
>> + 当你有了这些堆叠在一起的层时，你要知道它们是一些从简单到复杂的特征序列
>> + 卷积神经网络整体上来看  
>> &emsp; 是一个输入图片，让它通过很多层，第一个是**卷积层**( CONV ), 然后通常是**非线性层**( ReLU 就是一种非常常用的手段)，接下来会用到池化层( POOL )，这些措施已经大大降低了激活映射的采样尺寸，经过这些处理之后最终得到卷积层输出，然后我们就可以用我们之前见过的全连接层，连接所有的卷积输出，并用其获得一个最终的分值函数  
 >> + Output size:  
 >> **(N - F)/stride + 1**  
>> N 为输入的维度，F 为卷积核大小，滑动时的步幅为 stride  
>> **例：**  
>> N = 7, F = 3, stride = 1    
>> &emsp; 输出 5 \* 5  (最终输出 5 \* 5 \* 你使用的卷积核的数目)  
>> if 1 padded pixels( 0 补填像素)  
>> &emsp;实际七个卷积核都可以拟合，所以结果是一个 7 \* 7 的输出,这时的 N ≠ 7， N = 9  
>> + 做零填补的方式是，保持和我们之前的输入大小相同  
>> &emsp; 我们开始用的是7 \* 7，如果只是让卷积核从左上方角落处开始，将所有东西填入，那么之后我们会得到一个更小的输出，当我们会想保持全尺寸输出   
>> + **池化**：池化层所要做的就是要让所生成的表示更小且更容易控制，为了最后有更少的参数(降采样)  
&emsp;我们不会做在深度方向上的池化处理，而是只做平面上的，所以输入的深度和输出的深度是一样的  
> 计算公式同上 卷积(**但一般不再池化层做填零**)  
&emsp;最常见的方法是 **最大池化法**  
> 池化层也有一个卷积核的大小，而且卷积核的大小和我们所要池化处理的区域大小是相同的，不同的是这里不做数量积的计算，而是取该区域的最大值  
> **对于池化层，通常设定步长，使它们不会互相重叠,池化层没有参数(参数即我们需要训练的权重)**
> + #### 视觉之外的卷积神经网络  
>> + 有一个 5 \* 5 的卷积核，我们也可以称它为这个神经元的一个 5 \* 5的感受野(receptive field)，  
+ ## 训练神经网络  
> + #### 激活函数  
>> &emsp;我们输入数据，在全连接层或者卷积层，我们将输入乘上权重值，然后将结果输入一个激活函数或者非线性(单元)  
>> + **sigmoid 函数**   
>>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/1.png)  
>>> &emsp; 每个元素被输入到 sigmoid 非线性函数中，每个元素被压缩到[0,1]范围内，输入+∞，输出将无限趋近于1；输入-∞，输出将无限接近于0，在横坐标接近于0的区域中，我们可以将这部分看作是线性区域  
>>> &emsp; sigmoid 函数在某种意义上，可以被看作是一种神经元的饱和放电率  
>>> + 3 problems:  
>>> &emsp; 1.当输入 x 等于一个很大的负值或很大的正值时，它们位于 sigmoid 函数的平滑区域，这些区域会使梯度消失，从而无法得到梯度流的反馈  
>>> &emsp; 2.sigmoid outputs are not zero-centered  
>>> &emsp; 3.exp() is a bit compute expensive  
>> + **tanh 激活函数**  
>>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/2.png)  
>>> &emsp; 和 sigmoid 函数很相似，不同在于， tanh 被挤压到[-1,1]的范围内  
>>> &emsp; tanh 函数是以 0 为中心的(所以不会有 sigmoid 函数的第二个问题)  
>>> &emsp; 当它饱和时依然会出现梯度消失问题   
>> + **ReLU 激活函数**  
>>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/3.png)  
>>> f(x) = max(0,x)   
>>> &emsp; 若输入为负数，输出为 0；  若输入为正数，输出为其本身  
>>> + advantages:   
>>> &emsp;  x为正时不会存在饱和;   
>>> &emsp; 计算成本不高；   
>>> &emsp; 收敛速度比上两个快大约 6 倍；   
>>> &emsp; 比 sigmoid 更具生物学的合理性  
>>> + problems:  
>>> 不是以 0 为中心的  
>>> 虽然正半轴不产生饱和，但是负半轴饱和  
>> + **Leaky ReLU 激活函数**  
>>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/4.png)  
>>> f(x) = max(0.01x, x)  
>>> + advantages:    
>>> &emsp; x为正时不会存在饱和;   
>>> &emsp; 计算成本不高；   
>>> &emsp; 收敛速度 sigmoid/tanh 上两个快大约 6 倍；  
>>> &emsp; will not "die"  
>>> + **&emsp;Parametric Rectifier(PReLU) 参数整流器:**  f(x) = max(αx, x)  
>> + **指数线性单元 (ELU)**  
>>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/5.png)  
>>> + advantages:  
>>> &emsp; 具有 ReLU 的所有优点  
>>> &emsp; 输出均值接近为 0  
>>> &emsp; 和 ReLU 相比，ELU 没有在负区间倾斜，一些有争议的观点： 这样使得模型对噪音具有更强的鲁棒性  
>> + In practice:
>>> + Use <font color = #7FFFD4>ReLU</font>. Be careful with your learning rates  
>>> + Try out <font color = #DEB887>Leaky ReLU/ Maxout/ ELU</font>  
>>> + Try out <font color = #ff0000>tanh</font> but don't expect much    
>>> + <font color = #ff0000>Don't use sigmoid</font>  
> + #### 初始化权重  
>> + First idea: **Small random numbers**(适用于小型网络)
>> + 在开始训练时，初始化的权重值(即 W 参数)  
>> + 如果权重太小，在学习深度网络时，激活值会消失；  
>> + 如果权重初始值过大 ，那么这些初始值不断地乘以你的权值矩阵，将会爆炸增长  
>> &emsp;**Reasonable initialization:**  Xavier初始化法 initialization  
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/6.png)  
>> &emsp;ReLU 由于有一般的神经元被置 0 ，(和之前未用 ReLU 激活函数相比)等效的输入，实际只有一半的输入，所以只需要除以 2 这个因子， done.
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/7.png)
> + #### 数据预处理  
>> &emsp; 在卷积神经网络中，中心化和归一化是非常常用的手段，它会使数据分布均值为零，方差为一  
>> &emsp; 使用归一化，我们的损失函数对参数值中地小扰动就不那么敏感了； 如果神经网络中，某一层地输入均值不为 0 ，或者方差不为 1，该层网络权值矩阵地微小摄动，都会造成该层输出的巨大摄动    
>> + **batch normalization(批量归一化)**  
>> &emsp; 即在神经网络中加入额外一层以使得中间的激活值均值为0方差为1  
>> &emsp;  在batch normalization中，正向传递时，我们用小批量地统计数据计算平均值和标准差，并用这个估计值并且对数据进行归一化，同时还有缩放函数和平移函数来增加一层地可表达性   
> + #### 监督学习  
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/8.png)  
> + #### hyperparameter search(超参数搜索)  
>> + 网格搜索，随机搜索，当你的模型性能对某一个超参数比对其他超参数更敏感的时候，随机搜索可以对超参数空间覆盖的更好  
>> + 粗细粒交叉搜索，当你做超参数优化的时候，一开始可能会处理很大的搜索范围，几次迭代后，就可以缩小范围，圈定合适的超参数所在的区域，然后在对这个小范围，重复这个过程，可以多次迭代上述步骤，以获得超参数的正确区域  
> + #### Fancier Optimization(更好的优化)   
>>  + **随机梯度下降(SGD)**  
>>> 首先评估一下一些小批数据中损失的梯度，更进一步，向梯度为负的方向更新参数向量，重复这个过程，它在红色区域收敛，得到很小的误差值  
>>> + problem one： ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/9.png)  
>>> + problem two:  
>>> &emsp; **局部极小值**或**鞍点**，会卡在那里  
>>> &emsp; 在一维问题上，局部极小值看起来是个大问题，鞍点看起来不需要担心； 在高维空间相反  
>>> + problem three:  
>>> &emsp; 随机性，我们通常使用小批量的计算对损失和梯度进行评估
>>
>> + **SGD + Momentum(加动量)**  
>>> &emsp; 保持一个不随时间变化的速度，并且我们将梯度估计添加到这个速度上，然后在这个速度的方向上步进，而不是在梯度的方向上步进  
>>> &emsp; 类似于惯性，使得运动到局部极小值点或者鞍点时，虽然剃度为0，但是仍存在一个速度得以继续前进  
>>> &emsp; 有时会看到动量的一个轻微变化，叫做 Nesterov 加速梯度(动量)  
>> + **Nesterov Momentum**  
>>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/10.png)   
>>>&emsp; 现在更新速度，根据之前的速度来前进一步，然后计算此处的梯度，现在，当我们前进下一步时，我们实际是在速度的方向上步进，
换元后， Nesterov 可以同时计算损失函数和梯度；   
>>> &emsp; Nesterov 动量包含了当前速度向量和先前速度向量的误差修正  
>> + **AdaGrad 算法**
>>> &emsp; 你在优化的过程中，需要保持一个在训练过程中的每一步的梯度的平方和的持续估计，与速度项不同的是，现在有了一个梯度平方项，在训练时，我们会一直累加当前梯度的平方到这个梯度平方项，当我们更新参数向量时，我们会除以这个梯度平方项  
>> + **RMSProp 算法**  
>>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/11.png)   
>>> &emsp; 在 RMSProp 中，我们仍然计算梯度的平方，但是并不是仅仅简单的在训练中累加梯度平方，而是会让平方梯度按照一定比率下降，类似于动量优化法，我们是给梯度的平方加上动量，而不是给梯度本身  
>>> &emsp; 在计算完梯度后，取出当前的梯度平方，将其乘以一个衰减率，然后用1减去衰减率乘以梯度的平方加上之前的结果  
>> + **接近Adam 的算法**  
>>>  ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/12.png)   
>>> &emsp;使用 Adam 算法更新第一动量和第二动量的估计值，在红框里，我们让第一动量的估计值等于我们梯度的加权和，我们有一个第二动量的动态估计值，一个梯度平方的动态近似值  
>>> &emsp; 使用第一动量，有点类似于速度，并且除以第二动量，或者说第二动量的平方根，就是这个梯度的平方项  
>>> &emsp; problem:在最初的第一步会得到一个非常大的步长，是因为我们人为的把第二动量设为0造成的  
>> + **Adam(full form)**  
>>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/13.png)   
>>> 在我们更新了第一和第二动量之后，构造了第一和第二动量的无偏估计，通过使用当前时间t，现在实际上在使用无偏估计来做每一步更新，而不是初始的第一和第二动量的估计值  
>>> &emsp; **将 beta1 设置为 0.9，beta2 设置为 0.999， 学习率为 1e-3 或 5e-4，无论使用什么网络架构，都可以从这个设定开始**  
>> ****  
>> &emsp; **学习率：** 这些优化算法都有这个超参数，挑选x学习率的技巧：  
>> &emsp; 我们不必在整个训练的过程中都一直固定使用同一个学习率，有时候会把学习率沿着时间衰减  
>> &emsp; 一个衰减的策略时步长衰减，还有指数衰减  
>> &emsp; **设置学习率衰减的方法：** 先尝试不用衰减，看看会发生什么，仔细观察损失曲线，看看你希望在哪个地方开始衰减  
>> + **一阶优化**  
>>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/14.png)   
>>> &emsp; 在该红点求一个梯度，我们用梯度信息来计算这个函数的线性逼近，这个相当于是对函数进行的一阶泰勒逼近，假设一阶逼近就是实际的函数，然后我们想要迈出一步来找到逼近的最小值，但这个逼近在稍大的区间内并不成立，所以不能朝那个方向一下走太多；事实上，这里梯度的想法用上了函数的一阶偏导  
>> + **二阶优化**  
>>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/15.png)   
>>> &emsp; 同时考虑一阶和二阶偏导信息，对函数做一个二阶泰勒逼近，就是用一个二次函数来局部逼近我们的函数，因为是二次函数，可以直接跳到最小值点。
>> + **牛顿法**  
>>> &emsp; 把二阶优化的思想推广到多维的情况，会得到一个叫**牛顿步长**的东西，计算这个海森矩阵，即二阶偏导矩阵，接着求这个海森矩阵的逆，以便直接走到对你的函数用二次逼近后的最小值的地方  
>> + **拟牛顿法**  
>>> &emsp; 不是直接去求完整的海森矩阵的逆，而是去逼近这个矩阵的逆，常见的是低阶逼近  
>> + **L-BFGS(一个二阶优化器)**  
>>> &emsp; 对随机的情况处理的不是很好  
>> + **in practice:**  
>>> + 对很多不同的神经网络问题，Adam 是一个很好的选择  
>>> + 如果能够承受整个批次的更新，而且问题没有很多随机性，就可以使用 L-BFGS   
>> *****  
>> &emsp; 上述的所有优化策略都是在减少训练误差和最小化目标函数，而我们在意的是减少训练无耻和测试误差之间的差距  
>> &emsp; 如果已经很擅长优化目标函数，要怎么做来减少训练和测试之间的误差差距呢？  
>> &emsp; **Model Ensembles(模型集成)：**   
>>> + 训练更多的独立的模型  
>>> + 到测试时，评价他们的预测结果  
>>> 还可以在训练中保留多个模型的快照，然后用这些模型来做集成学习
> + #### Regularization(正则化)  
>>  &emsp; 我们在模型中加入一些成分来防止训练中的过拟合，提高单一模型的效果  
>> + **Add term to loss**  
>>> &emsp; 在损失函数上加入额外的一项正则项  
>> + **Dropout**  
>>> &emsp; 每次在网络中正向传递时，在每一层随机将一部分神经元置零，每次处理网络中的一层，算出这一层的值，随机将其中一些置零，然后继续在网络中前进**(将激活函数置零，每一层都是在计算上一个激活函数的结果乘以权重矩阵，得到下一个激活函数前的结果，然后计算激活函数，将其中一部分置零，那么下一层拿到的激活函数结果就有一部分是零) (一般试自全连接层，有时在卷积层也能看到，但卷积层是随机把整个特征映射置零)**  
>> + **batch normalization**  
>>> &emsp; 在测试中，基于全局估计的正则化来抵消这个随机性，而不是每一小批量估算，类似于dropout正则化效果  
>> + **Data Augmentation(数据增强)**  
>>> &emsp; 有一个最初的版本，有自己的数据，有自己的标签，每一次迭代中，我们使用它去更新我们的卷积神经网络，但我们可以以某种方式随机地转换图像，使得标签可以保留不变，然后用这些随机转换的图像进行训练，而不是原始的图像；然后再测试过程中，通过评估一些固定的裁剪图像来抵消这种随机性  
>>> &emsp; 有时会使用色彩抖动  
>> + **DropConnect**  
>>> &emsp; 和 dropout 同样的想法，但不是在每次正向传播中将激活函数置零，而是随机将一些权重矩阵的一些值置零  
>> + **Fractional Max Pooling(部分最大池化)**  
>>> &emsp; 每次在池化层操作时，随机池化我们正在池化的区域  
>> + **Stochasti Depth(随机深度)**  
>>> &emsp; 我们有一个很深的网络，在训练时，我们随机的从网络中丢弃部分层，消除一些层，只用部分层； 在测试时，用全部的网络
> + #### Transfer Learning(迁移学习)  
>>  &emsp; 迁移学习能够打破** “你需要超大的样本集，才能训练卷积神经网络”** 的说法  
>> &emsp; 首先使用你的卷积神经网络，在一个非常大的数据集训练，把从这个数据集中训练出的提取特征的能力用到你更感兴趣的小的数据集上  
>> + 修改从最后一层的特征到最后的分类输出之间的全连接层，需要重新随机初始化这部分矩阵，重新初始化最后的矩阵，冻结前面层的权重，现在只需要训练一个线性分类器，只需要训练最后这层，让它在你的数据上收敛  
>> + 如果数据稍微充裕一点，可以尝试微调整个网络，在最后一层收敛，在数据集上充分训练之后，试着更新整个网络的权值  
>>
>> &emsp; **通用的策略：更新网络时，将学习率调低**
+ ## 神经网络模型  
> + #### AlexNet  
>> &emsp; 九层卷积网络
> + #### VGG
>> &emsp; 拥有 16 层和 19 层的模型  
>> &emsp; 首先训练了一个 11 层的模型，能使其收敛，然后再中间添加一些额外的随机层继续训练，便得到了 16 层和 19 层的模型，
> + #### GoogleNet  
>> &emsp; 22 层模型  
>> &emsp; 有一些辅助分类器，它们被添加在网络的下层，这些都不是为了获得更好的分类性能所需要的，这是一种可以将额外的梯度直接注入到网络下层中的方法
> + #### ResNet  
>> &emsp; 这些残差网络是通过一些快捷连接，也就是小的残差块，我们将输入通过残差块，得到输出，然后再添加输入到残差块，从卷积层得到输出
+ ## 循环神经网络(RNN)  
> &emsp; **"Vanilla" Neural Network** ，所有的网络架构都有这种基础架构，会接收一些输入,输入是固定尺寸的对象，它在通过一些隐层后，给出单一的输出结果，比如一个分类，或针对某组类别的分类   
> + **Recurrent Neural Networks: Process Sequences**
>> + #### one to many  
>> &emsp; e.g. Image Captioning** (输入固定尺寸，输出一段可变长度的序列)**  
>> &emsp; image -> sequence of words  
>> + #### many to one  
>> &emsp; e.g. Sentiment Classification** (输入尺寸可变)**  
>> &emsp; sequence of words -> sentiment  
>> + #### many to many  
>> &emsp; e.g. Machine Translation**(输入输出的尺寸都可变)**  
>> &emsp; seq of words -> seq of words  
>> + #### many to many  
>> &emsp; e.g. Video classification on frame level  
>> &emsp; 例如一段有序的视频，帧数是一个变量，我们要对该序列中的每个元素做出决策，在输入是视频的情况下，这一过程可能是对每一帧都做分类决策   
>
> &emsp; **RNN 就是用于处理大小可变的有序数据的一类模型**  
> #### &emsp; 每个 RNN 网络都有一个小小的循环核心单元，它把 x 作为输入，将其传入 RNN ，RNN 有一个内部隐藏态(internal hidden state)，这一隐藏态会在 RNN 每次读取新的输入时更新，然后当模型下一次读取输入时，这一内部隐藏态会将结果反馈至模型  
> #### &emsp; RNN 模式：它读取输入，更新隐藏态，并且生成输出  
> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/16.png)  
> + #### 沿时间的截断反向传播方法  
>> &emsp; 即使我们输入的序列很长，甚至趋近于无限，我们在训练时，前向计算若干步，计算子序列的损失值，然后沿着这个子序列反向传播误差，并计算梯度更新参数，然后重复，仍然会得到网络中的一些隐藏状态，那是我们从第一批计算中得到的，现在当我们计算下一批数据时，我们使用这些隐藏状态，所以前向计算过程是相同的，但是现在当我们基于下一批数据计算梯度时，我们只能根据第二批数据反向传播误差，现在我们基于沿时间的截断反向传播法，计算一次梯度  
> + #### 语言模型、图像标注模型 、 视觉问答模型、 Soft attention模型
> + #### Vanilla RNN
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/17.png)   
>> &emsp; 不断乘以相同的权重矩阵
>> + 最大奇异值 > 1, **梯度爆炸**  
>> &emsp; **梯度截断：** 在我们计算梯度后，如果梯度 L2 范式大于某个阈值，就将它剪断，这样梯度就有最大阈值
>> + 最大奇异值 < 1, **梯度消失**  
>> &emsp; 换一个更加复杂的 RNN 结构，这就是使用 **LSTM** 的原因  
+ ## LSTM(长短记忆网络)  
> &emsp; 是循环神经网络的一种更高级的递归结构， LSTM 被设计用来解决梯度消失和梯度爆炸问题。  
> &emsp; 我们不是直接在输出上想办法，而是设计一些更好的结构来获取更好的梯度流动
> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/18.png)   
> &emsp; LSTM 中，在每个时间步中都维持两个隐藏状态，一个是 **ht**，就简单叫做**隐藏状态**(可以类比 banilla 循环神经网络中对应的隐藏状态)，第二个向量 **ct**，叫做**单元状态**，这个叫做单元状态的向量相当于保留在 LSTM 内部的隐藏状态，并且不会暴露到外部去  
> &emsp; 如上图，一开始使用两个输入，来计算四个门(即 i, f, o, g)，使用这些门来更新**单元状态 ct**，然后将这些单元状态(作为参数)，来计算下一个时间步中的隐藏状态
> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/19.png)   
> --------------------------------------------------------------------------- ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/20.png)  
> \---------------------------------------------------------------------------
> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/21.png)  
+ ## GRU(门控循环单元)  
> &emsp; 类似于 LSTM,在 GRU 单元中，使用元素乘法门和加法一起相互作用，以避免梯度消失问题  
+ ## 识别和分割  
> + #### Semantic segmentation(语义分割)  
>> &emsp; 我们希望输入图像，并对图像中每个像素做分类  
>> &emsp; 首先确定分类，就像做图像分类一样，不过是为每个像素产生一个分类坐标  
>> + **Sliding Window(滑动窗口)** (复杂度太高)   
>> &emsp; 将输入图像打碎为许多小的局部的图像块，可以用这些小块做分类，每一块它的中心像素属于哪类  
>> + **Fully Convoluntional(全连接卷积网络)**  
>> &emsp; 不光是从图像中提取各个图像块并且分类，可以把网络看成很多的卷积层堆叠在一起，这里只有卷积层  
>>> + **Unpooling(将2\*2变回4\*4)**  
>>> &emsp; 在去池化区域，重复每个元素  
>>> &emsp; 钉床函数(bed of nails)去池化，把所有值设为 0 ，除了 2\*2中的数字  
>>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/23.png)
>>> + **Max Upooling**  
>>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/22.png)
>>> + **Transpose Convolution(卷积转置)**  
>>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/24.png)  
> + #### 分类和定位  
>> &emsp; 定位的情况是，你提前知道会有一个或多个物体是你要找的，但是预先知道我们要对这个图像做分类决策，我们只产生一个边界，这个边界告诉我们物体在图像中哪里，我们有时称这个为 task    
> + #### 对象识别  
>> &emsp; 根据输入的图像，每当在图像中出现其中一类对象时，围绕对象划定一个框，并预测该对象从属的类别，这和分类与定位不同，因为对应每一张输入图像，对象的数量是不定的  
>> + **Sliding Window**  
>> &emsp; 类似于图像分割方法中，将图像切分为小块一样，也可以将其应用到对象识别中  
>> + **Region Proposals(候选区域)**  
>> &emsp; 建立候选清单，所以对给定的输入图像，候选区域网络会在对象周围给出上千个框，这时就可以进行定位，也就是寻找图像的边界，划定闭合的限定框  
>> &emsp; 首先选取候选区域网络，找到物体可能存在的备选区域，再应用卷积神经网络对这些备选区域进行分类，这样做比穷尽所有可能的位置和范围要来得更容易一些
>> + **R-CNN** (很慢)  
>> &emsp; 给定我们的输入，我们运行一些区域选择网络，去找到备选区域，有时候也叫兴趣区域或 ROI ，选择查找，可以给你大概2000个兴趣区域，但是这些输入中的区域可能有不同的尺寸，但是都要在卷积神经网络中运行，做分类，这样的话，我们希望所有输入尺寸一致，因为全连接层的特性，所以我们需要处理这些区域调整为固定尺寸，使之与下游网络输入相匹配，所以我们需要根据备选区域的要求对输入做切分至固定尺寸，之后经过卷积神经网络运行这些算法，然后使用支持向量机算法(SVM)基于样本做分类，预测对应的组别  
>> &emsp; 基于区域选择的卷积神经网络可以做回归  
>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/25.png)   
>> + **Fast R-CNN**  
>> &emsp; 现在不再按兴趣区域处理，而是让整个图像通过一些卷积层去运行，得到整个图像的高分辨率特征映射，我们仍旧要用一些备选区域，但不是固定算法，比如选择搜索，而不是针对备选区域切分图像的像素，现在考虑基于备选区域投影到卷积特征映射，之后从卷积特征映射提取属于备选区域的卷积块，而不是直接截取备选区域，通过对整个图像进行处理，可以重用很多卷积计算； 如果在下游有很多全连接层，这些全连接层的输入应该是固定尺寸的，所以我们需要对从卷积映射提取的图像进行整形，用可微的方法，用兴趣区域池化层，当你通过卷积特征映射，得到这些小块，你可以通过全连接层运行这些输入，预测分类结果  
>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/26.png)    
>> + **Faster R-CNN**  
>> &emsp; 问题是用固定函数计算备选区域成为瓶颈，我们让网络自身去做这个预测，用同样的方法，我们在卷积层中，运行整个输入图像，去获得特征映射，来表示整个高清晰度图像，现在有一个分离备选区域网络工作于卷积特征的上层，在网络内部预测自己的备选区域，当我们有了这些备选区域后，这就像一个 Fast R-CNN  
>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/27.png)
>> + **YOLO / SSD**  
>> &emsp; 这类思想不是对这些候选框分别进行处理，而是尝试将其作为回归问题处理，借助于大型卷积网络，所有预测一次完成  
>> &emsp; 给出输入图像，你可以将输入图像分成网格，在每个单元，你可以想象一系列的基本边界框，现在你想对每个网格和每个基本边界框预测几种目标物体， 1.你要预测边界框偏移，从而预测出边界框与目标物体的位置的偏差； 2.你还要预测目标对应类别的分数。 所以每个边界框都会对应一个类别分数，就是某类目标物体出现在边界框中的可能性有多大  
>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/28.png)  
>> &emsp; 从输入图像中，我们预测出这个 7\*7\*(5B+C) 的张量，我们有B个基本边界框，每个边界框对应5个值，分别对应边界框的差值和我们的置信度，C 对应 C 类目标类别的分数。  
>> &emsp; 我们可以把这种目标检测看作输入一张图像，输出一个 3 维张量  
> + #### Instance segmentation(物体分割)  
>> &emsp; 给定一张输入图像，我们想预测出一个位置和在图像该位置的物体对应的类别，就像对象识别，但是不是只预测出每个目标的边框，而是想要预测出整个分割区域，对于每个物体，预测输入图像的那些像素对应着预测物体，像是混合了语义分割和对象识别的方法  
>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/29.png)  
>> + **Mask R-CNN**  
>> &emsp; 我们取整张输入图像，将整张输入图像送入卷积和网络中训练好的候选框生成网络(这个和 Fater R-CNN 十分相似)，得到训练好的候选框后，我们把这些候选框投射到我们的卷积特征图上，但现在不是进行分类或回归预测边界框，我们想对每一个候选区域，每一个边界框预测出一个分割区域   
>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/30.png)
> + #### 总结
> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/31.png)  
+ ## Visualizing and Understanding(可视化和理解卷积网络)  
> + #### First Layer: Visualize Filters  
> &emsp; 卷积神经网络的第一个卷积层倾向于做一些类似于人类视觉系统早期阶段的工作，有向边和相反色  
> + #### Last Layer: Nearest Neighbors  
> &emsp; 我们通过神经网络运行，比如在神经网络的最后一个隐层，就是通过 4096 维的向量运行，因为在神经网络的末端，有完全连接层，我们所做的就是写出每个图像的 4096 维的向量，然后通过神经网络计算的 4096 维的向量计算相应的图像邻近  
> + #### Last Layer: Dimensionality Reduction(降维)  
> &emsp; **主成分分析(PCA):** 可以让你把像 4096维的特征向量的高维表示压缩到二维空间，以便让你更加直观的可视化这个特征空间  
> &emsp; **t-SNE(t-分布邻域嵌入):** 提取大量的图像，并让它们在卷积神经网络上运行，我们记录了每个图像在最后一层的 4096 维的特征向量， 而且 4096 维的特征向量数目非常庞大，现在我们通过 t-SNE 降维的方法，把 4096 维的特征空间压缩到二维特征空间，然后在压缩后的 2 维特征空间中布局网络，并且观察这个 2 维特征空间中网格中每个位置会出现什么类型的图像  
> + #### DeepDream  
> &emsp; 提取输入图像，通过神经网络运行到某一层，接着进行反向传播，并且设置该层的梯度等于激活值，然后反向传播到图像，并不断地更新图像。  
> &emsp; 关于(上述步骤的)解释是，试图放大神经网络在这张图像中检测到的特征，因为无论那层上存在什么样的特征，现在我们设置**梯度等于特征值**，以使神经网络放大他在图像中所检测到的特征  
> + #### Feature Inversion  
> &emsp; 选取一张图像，通过神经网络运行该图像，记录其中一个图像的特征值，然后根据它的特征表示重构那个图像，基于重建图像的样子，这将给我们一些在该特征向量中捕获的图像类型的信息，我们可以通过梯度上升和正则化来做到这一点，与其最大化某些分值，不如最小化捕获到的特征向量之间的距离，并且在生成图像的特征之间尝试合成一个新的与之前计算过的图像特征相匹配的图像  
> &emsp; 全变差正则化，将左右相邻像素之间的差异，拼凑成上下相邻，以尝试增加生成图像中特殊的平滑度  
> + #### Texture Synthesis(纹理合成)  
> &emsp; 给定一些纹理的输入图像块，现在我们想要构建某个模型，以使其生成更大块的相同的纹理图像  
> + #### Style Transfer(风格迁移)  
> &emsp; 把两张图像作为输入图像，第一步，选取其中一张图像，作为**内容图像**，它将引导我们的生成图像的主体，同样的，**风格图像** 负责生成图像的纹理或风格，然后共同做特征识别，通过最小化内容图像的特征重构损失以及风格图像的格拉姆矩阵损失，得到一张图，**这个图像在风格图像的艺术风格上呈现内容图像的内容**    
> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/32.png)  
> &emsp; **相对于 DeepDream 来说，这能让你更好的控制生成图像，在 DeepDream 中，你无法很好的控制最终会出现什么，只是选取神经网络的不同层,设置不同数量的迭代次数，然后物体出现在图片的各个角落**  
> &emsp; **但使用风格迁移，可以更好地控制以得到想要的结果，选取相同的内容图像和不同的风格图像，生成不同类型的图像；还可以调整其中的超参数因为我们在联合重构最小化内容图像的特征重构损失以及风格图像的格拉姆矩阵损失，如果平衡内容和风格图像之间权重以及损失，然后就可以控制内容和风格之间在生成图像的比重**  

 ## Supervised vs Unsupervised Learning  
> + #### Supervised Learning(监督学习)  
>  **Data:** (x, y)  
> x is data, y is label  
> **Goal:** Learn a function to map x -> y
> + #### Unsupervised Learning(无监督学习)  
> **Data:** x  
> Just data, no labels!  
> **Goal:** Learn some underlying hidden *structure* of the data  
> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/33.png)  
+ ## Generative Models(生成模型)  
> &emsp;  Unsupervised Learning下的一个模型
> &emsp; 在给定训练数据的情况下，我们的目标是从相同的数据分布中生成新的样本  
> &emsp; 生成模型可以解决密度估计问题  
> **Generative Models大方向分为显示密度模型和隐式密度模型，再分为很多小方向**
> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/34.png)   
> + #### PixelRNN AND PixelCNN  
>> &emsp; 这些都属于全可见信念网络，它们要做的就是对一个密度分布显式建模，那么在这种情况下我们有图像数据 x，同时我们想要对该图像的概率分布或者似然 p(x) 建模，我们使用链式法则将这一似然分解为一维分布的乘积，所以这里我们有每个像素 xi 的条件概率，其条件是给定所有下标小于 i 的像素(x1 到 xi-1)，这时图像中所有像素的概率或者联合概率就是所有这些像素点，所有这些似然的乘积   
>> \---------------------------------------------------------------
>>![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/35.png)  
>> \---------------------------------------------------------------
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/36.png)  
>> \---------------------------------------------------------------  
>> &emsp; **用 pixelCNN 训练要比用 PixelRNN 更快**  
>> **Pros:**  
>> &emsp; -pixelRNNs 和 pixelCNNs 能让你显示的计算似然 p(x)；  
>> &emsp; -该方法给出了一个很好的评估度量，可以通过你所能计算的数据的似然来度量出你的样本有多好   
>> &emsp; -能够生成很好的样本  
>> **Con:**  
>> &emsp; -Sequential generation => slow   
> + #### Variational Autoencoders(VAE)——变分自编码器  
>> &emsp; 这是通过向自编码器中加入随机因子获得的一种模型，在使用 VAE 时我们并不是直接取得确定的输入x，然后获得特征 z，最后再重构 x，而是采用了随机分布和采样的思想，这样就能从该模型中采样从而生成新数据，为了训练模型 VAEs 定义了一个难解的密度分布，我们能做的是推导出一个下界，然后优化这个下界，这个下界是变化的，那么变分实际上指的是用近似来解决这些难解的表达式  
>> &emsp; 这里我们假设训练数据，也就是X^(i)，i的范围从 1 到 N，该数据是从某种潜在的，不可观测的隐式表征 z 中生成的，z 的元素要捕捉的信息是在训练数据中某种变化因子的多少，那么这就像是在说它们(z 中的元素)可能是某种类似于属性的东西   
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/37.png)
>> &emsp; 编码器网络也是一种识别或者推断网络，因为我们实在给定 x 的条件下形成对该隐式表征 z 的推断的；而对于解码器网络，我们将用来执行生成过程，所以你也会听到有人称它为 生成网络  
> + #### GANs  
>> &emsp; 在GANs中，我们不再在显示的密度函数上下功夫，而是采用一个博弈论的方法，并且模型将会习得从训练分布中生成数据，而这一实现是基于一对博弈玩家的  
>> &emsp; 从一个简单点的分布中采样，然后习得一个从这些简单分布直接到我们想要的训练分布的一个变换  
>> &emsp; 生成器网络作为玩家1 会试图骗过判别器网络，欺骗的方式就是生成一些看起来十分逼真的图像； 同时第二个玩家，也就是判别器网络，将要试图把真实图片和虚假图片区别开来，那么判别器网络会尽可能的正确地指出哪些样本是生成器网络生成的赝品
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/38.png)   
>> + **总结：**  
>> &emsp; GANs 并不使用显式的密度函数，而是通过利用样本来隐式表示该函数，同时 GANs 会通过一种博弈论方法来训练，GANs 的优点是它们可以生成目前最好的样本，并且利用它们还能做很多事情；缺点就是训练起来需要更多的技巧，而且训练起来比较不稳定，我们并不是直接优化一个目标函数，事实上，我们需要努力地平衡两个网络的训练，这样就可能造成不稳定  
+ ## 深度增强学习  
> &emsp; 在强化学习的建立过程中，我们有一个代理和一个环境，环境赋予代理一个状态，反过来，代理将采取行动，然后环境将回馈一个奖励，这一过程将被循环，直到环境给出一个终端状态结束这个环节  
> + #### Markov Decision Process(马尔可夫决策过程)  
>> &emsp; 一个马尔可夫决策过程就是强化学习问题的数学表达，MDP 满足 Markov 性，即当前状态完全刻画了世界的状态  
>> &emsp; MDP 由一组对象定义，这个对象元组中有   
>> **-S(所有可能状态的集合)  
 -A(所有行动的集合)  
 -R(奖励的分布函数)  
 -P(表示下一个状态的转移概率分布，是给定一个状态行为组，将采取的动作)  
  -γ(折扣因子，用来对近期奖励以及远期奖励分配权重的)**  
>> &emsp; 马尔可夫决策过程的工作方式是，令我们的初试时间步骤 t 等于零，然后环境会从初始状态分布 p(s) 中采样，并将一些初始状态设为 0，然后从时间 t 等于零直到完成，我们将遍历这个循环，代理将选择一个动作 a下标t，环境将从这获得奖励，也就是给定状态以及刚刚采取的行动的条件下所获得的奖励，这也是抽样下一个状态，在时间 t+1，给定你的概率分布然后代理人将收到奖励，然后进入下一个状态，继续通过这个过程，再次循环，选择下一个动作，以此类推，直到结束  
>
> &emsp; 基于以上，我们可以定义一个策略 Π，它是一个从状态到行为的函数，它指定了在每个状态下要采取的行动，这可以是确定性的，也可以是随机的，而我们的目标是找到**最佳决策 Π\* ** ，最大限度地提高你的配权之后的全部奖励之和  
> + #### The optimal policy Π*   
>> &emsp; 最佳策略是能够最大化奖励总和的策略，最佳策略所提供的信息是在任意的给定状态下，我们应该采取什么行动来最大化我们将得到的奖励总和  
>> + **Vaule function and Q-vale function**  
>> &emsp; 任何情况下的有值函数，都是从状态 s 的决策到现在的决策之后的预期累计回馈  
>> &emsp; 用 Q值函数来定义在状态 s 时采取行动 a 有多好，那么可以得到最优 Q值函数(即Q*)，这是我们从给定的状态动作组下得到的最大期望累积奖励  
>> + **Bellman equation**  
>> &emsp; 给定任何状态动作组 s和a，这一对的价值就是你将要得到的回馈 r，再加上你最终进入的任何状态的价值(s'), 在状态 s' 上的值就会成为我们的行动上的最大值，**Q* 在 s' 状态下的 a'(最优Q值在s'状态下的最大行动值)**   
>> &emsp; 我们的最优策略是，在任何状态下按照具体的 Q\* 采取最好的行动， Q\* 将会告诉我们,可以从我们的任何行动中获得最大的未来回馈  
>>> + 值迭代算法  
>>> &emsp; 我们将通过 Bellman 方程作为迭代更新，在每一步中，通过试图强化 Bellman 方程，来改进我们对 Q\* 的近似  
>> + **Q-learning**  
>> &emsp; 使用函数逼近器来估计我们的动作值函数，如果这个函数逼近器是最近被使用的深度神经网络，那么这将被称为深度Q学习，作为深度强化学习的常用方法之一  
>> + **Experience Replay**  
>> &emsp; 保持这个状态转换的重放记忆表，如状态、行为、奖励、下一个状态，而且在游戏中不断获得的新的转换，当我们得到了更多的经验就可以不断更新这个表格  
>> &emsp; 现在我们可以做的是，就是训练我们的 Q网络，从回放记忆中取出一个小批量的转移样本，所以现在不是使用连续的样本，而是通过这些过渡样本进行抽样  
>> &emsp; 每个状态转移样本都可能对多次权重更新起作用，我们只是从这个表格抽样，所以可以多次抽样，具有更高的数据效率  
>> + **Actor-Critic 算法**  
>>> &emsp; 首先初始化策略函数 θ 和评价参数 Φ ，然后对于每一次训练的迭代，我们将在当前策略下，采样 M 个轨迹，我们将采用我们的策略并得到这些轨迹为 s0 a0 r0 s1等，然后计算我们想要的梯度，对每一个轨迹和每一个时间步骤我们都将计算其优势函数，然后使用优势函数接着把他们用于我们之前讨论过的梯度估算，并积累起来，然后我们将训练评价参数 Φ ，方法一样，增强这个价值函数来学习我们的价值函数，使这个优势函数最小化，这将促使它更接近我们之前所看到的这个 Bellman 方程  
> + #### Recurrent Attention Model(RAM or hand attention)  
>> &emsp; 循环聚焦模型，也被称为强制聚焦  
>> 思想：  
>> &emsp; 已经谈到的关于图像分类的强制聚焦的原始工作，你的目标还是预测图像类，但现在你要通过在图像周围一系列的微景来实现，你会看到图像周围的局部区域，你基本上将有选择地集中在这些部分周围观察来建立信息  
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/39.png)  
> + #### Summary  
>> - **Policy gradients(决策梯度)：** 直接在你的策略参数上进行梯度下降或上升。 **Challenge:** 采样效率  
>> - **Q-learning:** 不能保证总是有用，但当它工作时它会比决策梯度有更高的采样效率。 **Challenge：**  充分地探索  
>> ![](https://github.com/W-Avan/Machine_Learning/raw/master/pic/40.png) 
